\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsmath}
\usepackage{ dsfont }

\title{Вариационные Автоенкодеры с мультиномиальным Prior'ом.}
\author{Денис Мазур}
\date{Ноябрь 2018}

\begin{document}

\maketitle

\begin{abstract}
    Метод вариационных автоэнкодеров является, вероятно, самым эффективным
    среди методов глубинного обучения без учителя...
\end{abstract}

\section{Вступление}
Так как прочтение данной работы не предпологает ознакомленность с методами машинного обучения, будет дан поверхностый разбор некоторых ключевых принципов и методов,
необходимых для понимания вариационных автоенкодеров. 

От читателя предполагается понимание математического анализа, линейной алгебры и теории вероятности.

\section{Обучение нейронных сетей}
Для базового понимания автоенкодеров не требуется понимание принципа работы нейронных сетей, по этой причине объяснение устройства нейронных сетей было решено опустить 
и уделить больше внимания принципу их обучения. Для интересующихся, литература на тему нейронных сетей будет приложина в библиографии.

Для простоты устройсто нейронной сети можно редуцировать до некоторой функции, имеющей параметы $W$, принимающей значения $X$ и выдающей значения $\widehat{X}$. 
Физический смысл $X$ - данные, подаваемые на вход сети, $\widehat{X}$ - выход нейронной сети. Каждому элементу $x \in X$ соответсвует элемент $y \in Y$, и задачей обучения
нейронной сети является подобрать параметы $W$ нейронной сети так, чтобы они минимально или не отличались от $Y$. Также можно сформулировать задачу следущим образом:

$$d(f(x_n), y_n) \rightarrow \text{min}$$

Также, можно поставить задачу как поиск оптмальных параметров $W$:

$$\underset{W}{\textbf{argmin }} d(f(x_n), y_n)$$ 

Где $f(x)$ - нейронная сеть, а $d(x, y)$ определенная нами функция расстояния (отличия) между выходом нейронной сети и настоящим ответом, называемая функцией потерь.
Важно понимать следующие свойства функций $f(x)$ и $d(x, y)$, они обе дифференцируемые и определены на всех $X$, а это значит, что мы к параметрам нейронной сети $W$ можем
применять любые методы оптимизации функций, например, градиентный метод.

\subsection{Градиентный метод}
Градиентый метод является методом решения задач вида $\underset{a \in \mathds{R}^n}{\textbf{min }} g(x)$. Алгоритм градиентного метода начинается с выбора
параметоров $a$, это может делать как и из какого либо представления того какими примерно эти парамерты должны быть, так и случайным образом. Далее
идет так называемый "шаг" градиентного метода. Из параметров $a$ вычитаеся значение градента функции $g(a)$ в точке текущего значения $a$:

$$ a_{n + 1} = a_n - \nabla g(a_n)$$

Чтобы не "перескочить" через минимум функции во время итерации метода, градиент $\nabla f(x)$ обычно умножается на какую-то константу $\alpha$:

$$ a_{n + 1} = a_n - \alpha \nabla g(a_n)$$

\subsection{Градиентный метод в обучении нейронных сетей}
Теперь о том как градиентный метод может применяться в обучении нейронных сетей.

Функцию потерь нейронной сети $d(f(x_n), y_n)$ можно записать в виде, $d(f(x_n, W), y_n)$, до этого, для простоты, записи парамерты нейронной сети $W$ не записывались
как аргумент, хотя, очевидно, им являются. Поясню, что X и Y являются константными значениями, так как являются выборкой наших
данных и известны нам заранее. Таким образом, единственный аргумент, который мы можем изменять, минимизируя функцию потерь - $W$.

На практике, оптимизировать функцию потерь градиентным спуском "в лоб" не получится. У этого есть несколько причин, одна из главных - риск переобучения
модели (ситуация при которой модель показывает идеальных результат на обучающей выборке, но плохой на валидации). Но помимо этого, выборка данных
чаще всего слишком велика и не помещается в память компьютера, по этой причине на каждой итерации градиентного метода выбирается случайная подвыборка
тренировочных данных и над ней совершается шаг граиентого метода. Данный метод называется стохастическим градиентным спуском.

\end{document}