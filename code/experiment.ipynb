{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "from models import PMVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_APPROX = 10\n",
    "\n",
    "model = PMVAE(NUM_APPROX)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data and loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Lambda(lambda x: x.reshape(784)),\n",
    "                       ])),\n",
    "        batch_size=32, shuffle=True)\n",
    "\n",
    "def kl_div(mu, logsig, m, logs):\n",
    "    return 0.5 * torch.sum((logs - logsig - 1 + (logsig.exp() + (mu - m).pow(2))/logs.exp()))\n",
    "\n",
    "d_mus = torch.arange(0, NUM_APPROX)[None].expand(20, -1).float()\n",
    "d_sigmas = torch.log(torch.ones(20, NUM_APPROX))\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar, dec):\n",
    "    batch_size, _ = mu.shape\n",
    "    \n",
    "    true_mu = (d_mus[None].expand(batch_size, -1, -1) * dec).sum(2)\n",
    "    true_logvar = (d_sigmas[None].expand(batch_size, -1, -1) * dec).sum(2)\n",
    "    \n",
    "    bce = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction=\"sum\")\n",
    "    kld = kl_div(mu, logvar, true_mu, true_logvar)\n",
    "    \n",
    "    return bce + kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    loss_history = list()\n",
    "    \n",
    "    for batch_idx, (x, _) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_x, mu, logvar, dec = model(x)\n",
    "        \n",
    "        loss = loss_function(recon_x, x, mu, logvar, dec)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(x), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            loss_history.append(loss)\n",
    "            \n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 3431.373047\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 3618.229492\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 3656.746826\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 3875.216797\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 3705.769531\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 3863.190918\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 3669.397949\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 3723.055664\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 3572.587891\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 3635.821777\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-976bd84c7329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-e9895a83ef9a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_history = train(model, train_loader, optimizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'old_historyx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-034c93fca33a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_historyx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'old_historyx' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import distributions\n",
    "\n",
    "plt.plot(old_historyx)\n",
    "plt.plot(new_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb1eb124a20>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "\n",
    "normal = distributions.Normal(1, 1)\n",
    "\n",
    "plt.imshow(model.decode(normal.sample([1, 20])).view(28, 28).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))[0]\n",
    "x1, x2 = batch.chunk(2)\n",
    "\n",
    "(model.encode(x1)[-1][0] - model.encode(x2)[-1]).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
