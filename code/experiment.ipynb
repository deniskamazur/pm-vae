{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "from models import PMVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_APPROX = 10\n",
    "\n",
    "model = PMVAE(NUM_APPROX)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data and loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Lambda(lambda x: x.reshape(784)),\n",
    "                       ])),\n",
    "        batch_size=32, shuffle=True)\n",
    "\n",
    "def kl_div(mu, logsig, m, logs):\n",
    "    return 0.5 * torch.sum((logs - logsig - 1 + (logsig.exp() + (mu - m).pow(2))/logs.exp()))\n",
    "\n",
    "d_mus = torch.arange(0, NUM_APPROX)[None].expand(20, -1).float()\n",
    "d_sigmas = torch.log(torch.ones(20, NUM_APPROX))\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar, dec):\n",
    "    batch_size, _ = mu.shape\n",
    "    \n",
    "    true_mu = (d_mus[None].expand(batch_size, -1, -1) * dec).sum(2)\n",
    "    true_logvar = (d_sigmas[None].expand(batch_size, -1, -1) * dec).sum(2)\n",
    "    \n",
    "    bce = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction=\"sum\")\n",
    "    kld = kl_div(mu, logvar, true_mu, true_logvar)\n",
    "    \n",
    "    return bce + kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (x, _) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_x, mu, logvar, dec = model(x)\n",
    "        \n",
    "        loss = loss_function(recon_x, x, mu, logvar, dec)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(x), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 27255.425781\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 6142.104004\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 5546.905273\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 5373.910645\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 5073.679688\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 4312.281738\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 4895.722656\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 4303.705078\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 4270.954590\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 4083.658447\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 3951.914062\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 4050.032959\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 3884.449219\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 3516.541504\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 3616.600342\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 4026.264648\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 3763.521973\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 3439.914551\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 3696.238525\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, optimizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbbbcb73470>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch import distributions\n",
    "%matplotlib inline\n",
    "\n",
    "normal = distributions.Normal(3, 1)\n",
    "\n",
    "plt.imshow(model.decode(normal.sample([1, 20])).view(28, 28).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 784])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))[0]\n",
    "x1, x2 = batch.chunk(2)\n",
    "\n",
    "(model.encode(x1)[-1][0] - model.encode(x2)[-1]).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
