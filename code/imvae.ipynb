{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gumbel(shape, eps=1e-20):\n",
    "    U = torch.rand(shape)\n",
    "    return -torch.log(-torch.log(U + eps) + eps)\n",
    "\n",
    "def gumbel_softmax_sample(logits, temperature):\n",
    "    y = logits + sample_gumbel(logits.size())\n",
    "    return F.softmax(y / temperature, dim=-1)\n",
    "\n",
    "def gumbel_softmax(logits, temperature=0.1):\n",
    "    \"\"\"\n",
    "    input: [*, n_class]\n",
    "    return: [*, n_class] an one-hot vector\n",
    "    \"\"\"\n",
    "    y = gumbel_softmax_sample(logits, temperature)\n",
    "    shape = y.size()\n",
    "    _, ind = y.max(dim=-1)\n",
    "    y_hard = torch.zeros_like(y).view(-1, shape[-1])\n",
    "    y_hard.scatter_(1, ind.view(-1, 1), 1)\n",
    "    y_hard = y_hard.view(*shape)\n",
    "    return (y_hard - y).detach() + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMVAE(nn.Module):\n",
    "    def __init__(self, n_approx=5):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.n_approx = n_approx\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(784, 400),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            # (|mu| + |sigma| + |decision|) * num_gaussians\n",
    "            nn.Linear(400, 3 * 20 * n_approx),\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(20, 400),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Linear(400, 784),\n",
    "            nn.Sigmoid(),\n",
    "        )        \n",
    "        \n",
    "    def encode(self, x):\n",
    "        batch_size, _ = x.shape\n",
    "        mu, logvar, dec = self.encoder(x).chunk(3, dim=1)\n",
    "        \n",
    "        mu   = mu.view(-1, 20, self.n_approx)\n",
    "        logvar = logvar.view(-1, 20, self.n_approx)\n",
    "        # gumbel softmax over decision matrix rows\n",
    "        dec  = gumbel_softmax(dec.reshape(-1, self.n_approx)).view(-1, 20, self.n_approx)\n",
    "        \n",
    "        # 'choose' one component of every matrix row\n",
    "        return (mu * dec).sum(2), (logvar * dec).sum(2), dec\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = torch.Tensor.detach(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "        \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar, dec = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar, dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Lambda(lambda x: x.reshape(784)),\n",
    "                       ])),\n",
    "        batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_mus = torch.zeros(20, 1)\n",
    "d_sigmas = torch.log(torch.ones(20, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_div(mu, logsig, m, logs):\n",
    "    return 0.5 * torch.sum((logs - logsig - 1 + (logsig.exp() + (mu - m).pow(2))/logs.exp()))\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar, dec):\n",
    "    batch_size, _ = mu.shape\n",
    "    \n",
    "    true_mu = (d_mus[None].expand(batch_size, -1, -1) * dec).sum(2)\n",
    "    true_logvar = (d_sigmas[None].expand(batch_size, -1, -1) * dec).sum(2)\n",
    "    \n",
    "    bce = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction=\"sum\")\n",
    "    kld = kl_div(mu, logvar, true_mu, true_logvar)\n",
    "    \n",
    "    return bce + kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (x, _) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_x, mu, logvar, dec = model(x)\n",
    "        \n",
    "        loss = loss_function(recon_x, x, mu, logvar, dec)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(x), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PMVAE(1)\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(train_loader))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 17605.625000\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 6380.835449\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 5320.719727\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 5340.050781\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 4912.974121\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 4627.848145\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 3895.419922\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 3986.405518\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 4098.375000\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 4313.699219\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 4125.240234\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 3960.196289\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 4103.369629\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 3856.394287\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 3720.016357\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 3765.504395\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 4135.822266\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 3893.954346\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 4077.738770\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, optimizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8719dccd30>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(model.decode(torch.randn(1, 20)).view(28, 28).detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\tau \\rho \\iota \\alpha \\delta \\alpha$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
